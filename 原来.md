
\textbf{1) Stroke-Based Rendering (SBR): Mimicking Painting Techniques.} In the mid-1990s, Stroke-Based Rendering (SBR) emerged as a pioneering technique for mimicking painting styles. Researchers sought to simulate the look of oil painting or watercolor by layering "strokes" to construct an image with artistic textures. The core idea of SBR is to decompose an image into multiple strokes, each placed according to the shape and edge features of the image, building up layers that give the final image a painterly effect. Mathematically, SBR can be represented as:

\[
I_{\text{rendered}} = \sum_{k=1}^{N} S_k
\]

where \( S_k \) represents each individual stroke. While SBR is capable of producing a single, cohesive style, its reliance on fixed rules limits its flexibility, making it difficult to adapt to diverse styles.

\textbf{2) Region-Based Rendering: Introducing Local Style Control.} As research progressed, scientists explored methods to achieve multiple styles within a single image. Region-based rendering emerged as a technique that segments an image into various regions (such as sky, ground, trees), and applies different styles to each segment. This method brought a breakthrough in local style control for style transfer.

The core of region-based rendering lies in assigning appropriate style weights to each segmented region to achieve localized style control, expressed as:

\[
I(x, y) = \sum_{i=1}^{K} w_i(x, y) \cdot S_i(x, y)
\]

where \( w_i(x, y) \) represents the weight for region \( i \), and \( S_i(x, y) \) represents the style applied to that region. Although this method enhances control over local regions, its effectiveness depends on the accuracy of segmentation and struggles with dynamic style transitions.

\textbf{3) Example-Based Rendering: Introducing Learning Concepts.} Entering the 21st century, researchers began to introduce data-driven approaches to style transfer. In 2001, Hertzmann et al. introduced the "Image Analogies" method, representing this shift\cite{hertzmann2023image}. Example-Based Rendering learns the mapping between a stylized and non-stylized pair of images and applies it to a new input, producing a similar stylized effect. Unlike the fixed-rule methods, Example-Based Rendering leverages examples to capture style characteristics, representing an early attempt to incorporate "learning" into style transfer.

The goal of Example-Based Rendering is to find a mapping \( T \) such that, given a new input image \( I_s' \), it generates a stylized output \( I_t' \) similar to the target style:

\[
I_t' = T(I_s'; I_s, I_t)
\]

where \( T \) is the style mapping function, \( I_s \) and \( I_t \) are paired source and stylized images. While effective for simple style mappings, this method faces challenges in capturing complex, detailed styles.

\textbf{4) Image Filtering and Basic Artistic Effects: Simplified Enhancements of Edges and Blurring.} Around the same time, image filtering techniques became popular for generating simplified artistic effects. Filtering techniques use mathematical operations to adjust the edges and textures of an image, producing specific visual effects. Bilateral filtering and Gaussian blur are two commonly used techniques for creating simple cartoon-like or softened effects.

\begin{itemize}
    \item \textbf{Bilateral Filtering} is an edge-preserving smoothing technique, where the image is smoothed while preserving edge details. 

    \item \textbf{Gaussian Blur} applies a Gaussian kernel to soften the image, generating a dreamy effect. 

    \[
    I_{\text{blurred}}(x, y) = \sum_{x'} \sum_{y'} I(x', y') \cdot G((x, y) - (x', y'))
    \]
\end{itemize}

These filtering methods are computationally efficient and suitable for generating basic artistic effects, but they lack the sophistication required to portray complex, layered styles.

\subsection{The Debut of Deep Learning in Style Transfer}

Under the limitations of traditional image processing technology, it is difficult to simulate diverse artistic styles through style transfer. However, Neural Style Transfer (NST), proposed by Gatys et al. in 2015, provides a groundbreaking solution through deep learning \cite{gatys2015neural}. NST uses Convolutional Neural Networks (CNNs) to automatically extract content and style features, achieving effective decoupling of content and style. This technique leverages the powerful feature extraction capabilities of deep neural networks, enabling style transfer to achieve richer artistic effects and significantly enhancing algorithm flexibility.

The core of NST lies in defining two loss functions: content loss and style loss, which, through an optimization process, blend the structural features of the content image with the texture features of the style image. Content loss preserves the structure of the original content image, while style loss captures the texture and color characteristics of the style image. By minimizing these losses, NST achieves an effective and flexible style transfer, allowing the generation of artistic images that incorporate both the content and the stylized texture.

\textbf{1) Content Loss Function.} The content loss is used to preserve the structural information of the content image, defined as:

   \[
   \mathcal{L}_{\text{content}}(I_C, I_G) = \frac{1}{2} \sum_{i,j} \left( F^l_{I_C}(i,j) - F^l_{I_G}(i,j) \right)^2
   \]

   By minimizing this loss, the generated image progressively retains the structure of the content image, ensuring visual consistency with the content image.

\textbf{2) Style Loss Function.} The style loss captures the texture features of the style image, ensuring that the generated image has a similar visual style to the style image. NST employs a Gram matrix to calculate relationships between image features:

   \[
   G^l_{I}(i,j) = \sum_k F^l_{I}(i,k) F^l_{I}(j,k)
   \]


   where \( G^l_{I}(i,j) \) represents the correlation between channels \( i \) and \( j \) in the \( l \)-th layer feature map. By optimizing the style loss, the generated image can exhibit texture and color characteristics similar to those of the style image.

In the original Neural Style Transfer (NST) method, while the generated results were impressive, the approach relied on an iterative optimization process that was computationally slow, making it challenging to meet real-time application demands. To address this, Johnson et al. proposed a fast style transfer method based on perceptual loss, replacing the iterative optimization process with a pre-trained feed-forward network \cite{johnson2016perceptual}. This approach significantly improved the speed of style transfer while maintaining high image quality, allowing style transfer to be applied in real-time scenarios such as video stylization. Building on this, Ulyanov et al. introduced Texture Networks, another feed-forward style transfer method that bypassed iterative optimization to achieve similar real-time performance \cite{ulyanov2016texture}. Additionally, to further improve the consistency and quality of stylized outputs, especially in preserving fine textures, Ulyanov et al. proposed Instance Normalization, which normalizes each instance independently to eliminate batch dependencies and ensure stable style rendering \cite{ulyanov2016instance}. Together, these innovations made it feasible to use style transfer in low-latency environments, such as mobile devices, while improving both efficiency and image quality.

Although feed-forward networks improved the speed of style transfer, they still required significant computational resources. To address this, Ulyanov et al. proposed the Light Transfer method, which achieves efficient real-time style transfer through a lightweight network design. Compared to other methods, Light Transfer uses fewer parameters, enabling it to run on resource-constrained devices, such as embedded systems and mobile platforms \cite{ulyanov2017light}. This innovation made style transfer technology more accessible in low-resource environments, further promoting its practical applications. Lastly, Risser et al. proposed Histogram Loss to maintain color and texture consistency in style transfer. By using histogram matching, Histogram Loss enhances the tonal and textural details of the generated images, making the stylized imageâ€™s color and texture distribution more similar to the style image, thereby improving the visual consistency of the style transfer results \cite{risser2017histogram}. This method adds finer control over color and texture, making it particularly suitable for applications with high artistic quality requirements.

\subsection{Multi-style adaptation and style control}

In the original NST framework, each style transfer was limited to a single style. To meet the need for diverse style transfer, Huang and Belongie proposed the Adaptive Instance Normalization (AdaIN) method, which enables flexible style adaptation by normalizing the mean and variance of feature maps\cite{huang2017arbitrary}. The AdaIN method allows users to customize multiple different styles by adjusting the normalization parameters, thereby enabling arbitrary style transfer. The core formula of this method is:

\[
\text{AdaIN}(x, y) = \sigma(y) \left( \frac{x - \mu(x)}{\sigma(x)} \right) + \mu(y)
\]

where \( x \) represents the content features, \( y \) represents the style features, and \( \mu \) and \( \sigma \) denote the mean and standard deviation of the feature maps, respectively. The introduction of AdaIN brings a high degree of flexibility to style transfer, allowing for multiple styles to be transferred without retraining the model, greatly expanding the applications of NST.

In the initial AdaIN method, the model used fixed normalization parameters for each style, achieving flexible multi-style transfer but with limitations in detailed control. It was challenging to independently adjust styles across different regions of an image. To address this, Zhu et al. proposed Semantic Adaptive Instance Normalization (SEAN), which combines semantic segmentation information to divide the image into multiple semantic regions, assigning unique normalization parameters to each region. This approach enables fine-grained control over local styles, allowing different regions of an image to exhibit distinct style characteristics while preserving the overall style effect \cite{zhu2020sean}.

Building on the success of AdaIN, Huang et al. further improved the method in 2018 by proposing a more flexible approach to adaptive style transfer that retained AdaIN's dynamic style adjustments while enhancing adaptability across a wider range of styles without requiring retraining. This method optimizes AdaINâ€™s normalization operation by adjusting its parameters to better capture subtle variations in style, allowing the model to adjust to diverse style changes more seamlessly \cite{huang2018multimodal}. This advancement not only increases control over style intensity but also ensures smoother transitions across different styles within a single model, thus expanding AdaIN's applications in complex and dynamic style transfer tasks, such as interactive design and real-time video applications.

To further increase style control within AdaIN-based frameworks, researchers have introduced modifications that allow the user to influence style strength and feature blending in more nuanced ways. These methods enable AdaIN to incorporate style-specific traits while preserving the contentâ€™s structural integrity, making it suitable for high-fidelity and context-sensitive style applications. Together, these improvements underscore AdaIN's role as a foundational approach to adaptive style transfer, enhancing the adaptability, control, and applicability of style transfer technology across a range of domains.


\begin{table*}[h!]
\centering
\begin{tabular}{c|c|c|c|c|c}
\hline
\textbf{Year} & \textbf{\#} & \textbf{Method}  & \textbf{Publication} & \textbf{Innovation} & \textbf{Style Transfer Type} \\
\hline
2015 & \cite{gatys2015neural} & NST  & CVPR & CNN-based style transfer & Single \\
\hline
2016 & \cite{johnson2016perceptual} & Fast Transfer & ECCV & Real-time with perceptual loss & Single \\
\hline
2016 & \cite{ulyanov2016texture} & Texture Net  & arXiv & Feed-forward for fast stylization & Single \\
\hline
2016 & \cite{ulyanov2016instance} & Instance Norm & arXiv & Improved stylization & Single \\
\hline
2017 & \cite{li2017universal} & Universal Style  & NIPS & Feature transforms for arbitrary transfer & Arbitrary \\
\hline
2017 & \cite{ulyanov2017improved} & Light Transfer & CVPR & Lightweight real-time transfer & Single \\
\hline
2017 & \cite{huang2017arbitrary} & AdaIN  & ICCV & Adaptive instance normalization & Arbitrary \\
\hline
2017 & \cite{risser2017histogram} & Histogram Loss & CVPR & Histogram matching & Single \\
\hline
2018 & \cite{huang2018multimodal} & AdaIN & CVPR & Adaptive style transfer & Arbitrary \\
\hline
2020 & \cite{zhu2020sean} & SEAN  & CVPR & Semantic segmentation-based style control & Multi-region \\
\hline
\end{tabular}
\caption{Summary of Key Early Techniques and Traditional Methods in Style Transfer}
\end{table*}


### Comprehensive Image Style Transfer Research Compilation

| Year | Title                                                                                                            | Publication                            | Key Contribution                            | Technical Focus                  | paper                                                                                                                                                                   |
| ---- | ---------------------------------------------------------------------------------------------------------------- | -------------------------------------- | ------------------------------------------- | -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1995 |                                                                                                                  | IEEE Transactions on Signal Processing | Multi-scale image feature capture           | Wavelet-based image analysis     |                                                                                                                                                                         |
| 2001 |                                                                                                                  | ACM Transactions on Graphics           | Combining local and global textures         | Natural texture representation   |                                                                                                                                                                         |
| 2015 |                                                                                                                  | NeurIPS                                | CNN-based style/content separation          | Gram matrix feature extraction   |                                                                                                                                                                         |
| 2016 |                                                                                                                  | IEEE CVPR                              | Specialized convolutional network           | Rapid style transfer             |                                                                                                                                                                         |
| 2016 |                                                                                                                  | ICML                                   | Feed-forward style transfer                 | Real-time style generation       |                                                                                                                                                                         |
| 2016 |                                                                                                                  | Conference Publication                 | Stable style rendering                      | Normalization techniques         |                                                                                                                                                                         |
| 2017 |                                                                                                                  | Conference Publication                 | Efficient real-time style transfer          | Computational optimization       |                                                                                                                                                                         |
| 2017 |                                                                                                                  | Conference Publication                 | Color and texture consistency               | Statistical style matching       |                                                                                                                                                                         |
| 2017 |                                                                                                                  | Conference Publication                 | Balancing content and style loss            | Loss function design             |                                                                                                                                                                         |
| 2017 |                                                                                                                  | IEEE ICCV                              | Dynamic style feature adaptation            | Flexible style mapping           |                                                                                                                                                                         |
| 2017 |                                                                                                                  | Conference Publication                 | Attention mechanism                         | Neural network architecture      |                                                                                                                                                                         |
|      |                                                                                                                  |                                        |                                             |                                  |                                                                                                                                                                         |
| 2018 | # A Style-Aware Content Loss for Real-time HD Style Transfer                                                     | ECCV                                   |                                             |                                  | [link](https://compvis.github.io/adaptive-style-transfer/)                                                                                                              |
|      |                                                                                                                  |                                        |                                             |                                  |                                                                                                                                                                         |
| 2018 |                                                                                                                  | IEEE CVPR                              | Enhanced adaptive techniques                | Multi-style learning             |                                                                                                                                                                         |
| 2018 |                                                                                                                  | Conference Publication                 | Image self-encoded feature transfer         | Feature representation           |                                                                                                                                                                         |
| 2021 | Adaptive Convolutions for Structure-Aware Style Transfer                                                         | cvpr                                   |                                             |                                  |                                                                                                                                                                         |
|      |                                                                                                                  |                                        |                                             |                                  |                                                                                                                                                                         |
| 2020 |                                                                                                                  | IEEE CVPR                              | Semantic adaptive normalization             | Region-specific style transfer   |                                                                                                                                                                         |
| 2022 |                                                                                                                  | IEEE CVPR                              | Transformer-based transfer                  | High-resolution style generation |                                                                                                                                                                         |
| 2022 |                                                                                                                  | Conference Publication                 | Model pruning                               | Efficiency optimization          |                                                                                                                                                                         |
| 2023 |                                                                                                                  | Conference Publication                 | Enhanced multi-level content and style loss | Scale-invariant learning         |                                                                                                                                                                         |
| 2023 |                                                                                                                  | Conference Publication                 | Texture synthesis                           | Patch-based transfer             |                                                                                                                                                                         |
| 2023 | StylerDALLE: Language-Guided Style Transfer Using a Vector-Quantized Tokenizer of a Large-Scale Generative Model | iccv                                   |                                             |                                  | [link](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.pdf) |
|      |                                                                                                                  |                                        |                                             |                                  |                                                                                                                                                                         |



| Year | Publication                             |                                                       | Key Contribution                   | Technical Approach                |
| ---- | --------------------------------------- | ----------------------------------------------------- | ---------------------------------- | --------------------------------- |
| 2024 | NeurIPS                                 | Zero-Shot Style Transfer via Foundation Models        | Generalized style representation   | Cross-domain feature extraction   |
| 2024 | TPAMI                                   | Semantic Segmentation-Guided Style Transfer           | Precise regional style application | Segmentation-aware style mapping  |
| 2024 | Computer Vision and Image Understanding | Content-Preserving Style Transfer                     | Intelligent content protection     | Perceptual feature preservation   |
| 2024 | Pattern Recognition                     | Multi-Scale Style Integration                         | Cross-resolution style learning    | Scale-invariant feature transfer  |
| 2024 | WACV                                    | Texture Consistency Networks                          | Enhanced texture preservation      | Local feature matching algorithms |
| 2024 | ECCV                                    | Adaptive Style Normalization                          | Dynamic feature mapping            | Flexible style intensity control  |
| 2024 | ACM Multimedia                          | Lightweight Neural Style Transfer                     | Efficient mobile-friendly transfer | Compact neural network design     |
| 2024 | ICML                                    | Perceptual Loss Optimization                          | Advanced loss function design      | High-resolution style quality     |



diffusion

| Year | Title                                                                                        | Publication | Key Contribution | Technical Approach | Paper                                        |
| ---- | -------------------------------------------------------------------------------------------- | ----------- | ---------------- | ------------------ | -------------------------------------------- |
| 2024 | Tuning-Free Adaptive Style Incorporation for Structure-Consistent Text-Driven Style Transfer |             |                  |                    | [link](https://arxiv.org/html/2404.06835v1)  |
| 2024 | Z-STAR+: A Zero-shot Style Transfer Method via Adjusting Style Distribution                  |             |                  |                    | [link](https://arxiv.org/abs/2411.19231)     |
| 2024 | # InstantStyle-Plus: Style Transfer with Content-Preserving in Text-to-Image Generation      |             |                  |                    | [link](https://instantstyle-plus.github.io/) |


| Year | Title                                                                      | Publication | Key Contribution | Technical Approach | Paper                                    |
| ---- | -------------------------------------------------------------------------- | ----------- | ---------------- | ------------------ | ---------------------------------------- |
| 2019 | # A Style-Based Generator Architecture for Generative Adversarial Networks |             |                  |                    | [link](https://arxiv.org/abs/1812.04948) |
|      |                                                                            |             |                  |                    |                                          |
| 2024 |                                                                            |             |                  |                    |                                          |