
最初的**扩散模型（Diffusion Model**的原理来自于统计物理学，灵感来源于“布朗运动”和“扩散过程”中的噪声传播。早期的扩散模型用于生成数据是从自然的物理现象中获得启发，它模拟的是如何从一种分布逐渐扩散到均匀分布的过程。然后通过反向扩散过程，逐渐恢复原始的结构和数据。

最早提出的扩散模型在概率生成领域被称为**Denoising Diffusion Probabilistic Model (DDPM)**，由Jonathan Ho等人在2020年发表的一篇题为 **"Denoising Diffusion Probabilistic Models"** 的论文中首次系统介绍。这篇论文成为了扩散模型在生成模型领域的奠基之作。

论文提出了如何通过**去噪过程（denoising process**来实现高质量图像生成。最初的思想是将图像逐步加入噪声，然后学习一个反向的去噪过程，逐步从随机噪声中生成图像。与GAN不同，扩散模型具有稳定的训练过程，没有模式崩溃问题。

扩散模型的基本思想是利用“马尔可夫链”逐步加入噪声到数据中，然后通过学习如何逐步去除噪声来恢复原始数据。模型包括两个主要步骤：

- **前向过程（Forward Process）**：给定原始数据，我们将其逐步添加噪声，直到数据变成接近纯噪声的状态。这是一个渐进的过程，在每一步中添加少量噪声。

 $$
     
     x_t = \alpha_t x_0 + \sigma_t \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
     
     $$

 其中 \(\alpha_t\) 和 \(\sigma_t\) 是控制噪声添加的系数，\(t\) 是时间步数，\(\epsilon\) 是高斯噪声。



- **反向过程（Reverse Process）**：模型学习如何从接近纯噪声的状态逐步去噪，直到生成逼真的数据。这一过程是模型的核心部分，它需要通过优化一个基于最大似然估计的损失函数来学习去噪的步骤。

 $$
     p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
     $$

反向扩散过程通过神经网络（通常是UNet架构）来学习每个步骤的去噪操作。最终，模型可以从纯随机噪声中生成新的、高质量的图像。

扩散模型的训练主要依赖于**KL散度**，通过最小化前向和反向过程之间的差异，模型能够学习如何从噪声中恢复出原始数据。反向过程被认为是一个生成过程，从一个高维空间的噪声逐渐生成复杂数据。


