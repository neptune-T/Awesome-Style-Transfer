#### 2. Basic Concepts of Style Transfer

- **2.1 Historical Background of Style Transfer**
  - Evolution of traditional and modern style transfer methods

Image style transfer (Neural Style Transfer, NST) has its roots in earlier artistic rendering techniques and image processing methods, which aimed to simulate artistic styles through non-neural approaches. Traditional style transfer methods were primarily focused on handcrafted features and rule-based transformations. Modern approaches, however, leverage deep learning to capture complex features from both content and style images, allowing for more sophisticated and diverse transformations.

The evolution from traditional to modern style transfer can be understood through the following key phases:

1. **Traditional Artistic Rendering**: Early methods involved handcrafted techniques such as Stroke-Based Rendering (SBR) and Region-Based Techniques, where brushstrokes or segmentation were manually applied to simulate an artistic style. These methods lacked the ability to generalize across various styles and were limited by their reliance on predefined rules.

2. **Statistical Approaches**: Techniques like **Histogram Matching** and **Texture Synthesis** emerged to quantify the statistical properties of images, such as color distributions or texture patterns. In texture synthesis, a Markov Random Field (MRF) model was used to match local features between the content and style images, which allowed for better preservation of textures compared to rule-based methods. The optimization problem in MRF-based texture synthesis can be described by maximizing the following likelihood:

   $$
   P(I) = \prod_{i \in \Omega} P(I_i | N_i)
   $$

   where \( I \) is the synthesized texture, \( I_i \) is the pixel value at location \( i \), and \( N_i \) represents the neighborhood around pixel \( i \). This optimization ensures that the generated image matches the local properties of the reference texture.

3. **Neural Style Transfer**: The introduction of deep learning, particularly convolutional neural networks (CNNs), marked a significant breakthrough in style transfer. Instead of relying on handcrafted features, modern NST methods use feature maps extracted from pre-trained CNNs to represent both style and content. In 2015, Gatys et al. proposed the use of **Gram matrices** to quantify style by measuring the correlations between feature maps:

   $$
   G_{ij}^l = \sum_k F_{ik}^l F_{jk}^l
   $$

   where \( G^l \) is the Gram matrix at layer \( l \), and \( F^l \) represents the feature maps. This formulation captures the texture of the style image by analyzing the statistical dependencies between different channels in the feature maps.

4. **Feedforward Networks and Real-Time Transfer**: To overcome the high computational cost of iterative optimization, researchers developed feedforward networks for real-time style transfer. A generator network was trained to directly map a content image to a stylized output, significantly improving efficiency. The optimization problem for training the generator can be expressed as:

   $$
   L_{total} = \alpha L_{content} + \beta L_{style}
   $$

   where \( L_{content} \) represents the content loss, \( L_{style} \) is the style loss, and \( \alpha \), \( \beta \) are weights to balance the contributions of content and style.

- **2.2 Definitions of Style and Content**
  - Distinction and quantification of style and content features

In NST, the notions of style and content are critical for defining how the transformation is achieved. The content of an image refers to its overall structure and semantic elements, such as shapes, objects, and their spatial arrangement. The style, on the other hand, represents characteristics like colors, textures, and artistic elements that contribute to the visual identity of an artwork. Mathematically, the content is often extracted using features from deeper layers of a convolutional neural network (CNN), while the style is captured through statistical measures like the Gram matrix, which quantifies correlations between feature maps at different layers.

The Gram matrix \( G^l \) at layer \( l \) is calculated as:

$$
G_{ij}^l = \sum_k F_{ik}^l F_{jk}^l
$$

where \( F^l \) represents the feature map of the input image at layer \( l \). The Gram matrix captures the style by measuring the correlations between different channels of the feature map, thereby encoding texture information that defines the visual style.

#### 3. Early Techniques and Traditional Methods

- **3.1 Image Processing-Based Style Transfer Methods**
  - Overview of classic algorithms and techniques

Before neural networks were used for style transfer, traditional methods were employed to achieve artistic effects. These methods primarily relied on handcrafted techniques and image processing algorithms to manipulate visual characteristics.

- **Stroke-Based Rendering (SBR)**: This method simulates specific artistic styles by placing virtual brushstrokes (such as paint, tiles, or stipples) onto a digital canvas. The process starts with a source image, and brushstrokes are applied incrementally to recreate the image with an artistic appearance. However, each SBR algorithm is tailored to a specific style, limiting its versatility.

- **Region-Based Techniques**: These techniques use image segmentation to divide an image into different regions, which can then be rendered with different styles. The segmentation enables local control over the rendering process, allowing different brush effects for different parts of an image. Despite the improvement in flexibility, these methods still struggle with adapting to arbitrary artistic styles.

- **Example-Based Rendering**: The example-based approach learns a mapping between an unstylized and a stylized image to create analogous stylizations. This approach, also known as **image analogies**, relies heavily on training pairs of images and only captures low-level features, limiting its effectiveness in handling complex artistic styles.

- **Image Processing and Filtering**: Simple filters such as bilateral filtering or Gaussian differences were used to create artistic effects by enhancing edges or blurring textures. These methods are computationally efficient but fall short in producing diverse and sophisticated styles.

- **3.2 Handcrafted Feature Extraction and Style Transfer Research**

Early research on style transfer often involved handcrafted feature extraction methods, where specific image features, such as edges, textures, and color distributions, were manually defined and manipulated to achieve stylization.

- **Histogram Matching**: One common method was to match the color histogram of the target image to that of the style image. The transformation function \( T \) was applied such that:

$$
H_c(T(x)) = H_s(x)
$$

where \( H_c \) and \( H_s \) are the histograms of the content and style images, respectively. Although effective for basic color adjustments, this method lacked the capability to capture intricate artistic features such as brushstrokes or patterns.

- **Texture Synthesis**: Texture synthesis was another widely used technique, where the aim was to generate a new image \( I \) that matched the statistical properties of a given texture sample. A Markov Random Field (MRF) model was used to achieve this by modeling the probability of pixel values based on their neighbors. The synthesis process involved optimizing these probabilities to generate a plausible texture.

These handcrafted methods established fundamental principles of visual style representation, focusing on capturing and manipulating statistical properties of visual elements. However, they were limited in their ability to generalize across different styles and often lacked the capability to effectively combine content and style at a high level.

